
<!doctype html>
<html lang="en">
<head>

<!-- all praise to https://realfavicongenerator.net -->
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">

  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="/fonts.css">
  <link rel="stylesheet" href="/fontawesome-free-5.15.3-web/css/all.css">
  <link rel="stylesheet" href="/bootstrap.min.css">

  <script async src="https://cse.google.com/cse.js?cx=003601324460585362024:4xwpwgaitgd"></script>
  <script src="/react.min.js"></script>
  <script src="/react-dom.min.js"></script>
  <script src="/jeri.min.js"></script>
  <link rel="preload" href="/exr.worker.js" as="script" crossorigin="anonymous">

  <link rel="stylesheet" href="../pbrstyle.css">
  <script src="/3ed-2018/pbrt-display.js"></script>
        

  <title>Exercises</title>
</head>
        
<body>

<nav class="fixed-top-lg-navbar navbar navbar-expand">
  <ul class="nav navbar-nav">
    <a class="navbar-brand" href="../contents.html"><img src="../pbr.jpg" width=25 height=25></a>
    <li class="nav-item"><a class="nav-link" href="../Sampling_and_Reconstruction.html">Sampling and Reconstruction</a></li>
    <span class="navbar-text">/</span>
    <li class="nav-item"><a class="nav-link" href="#">Exercises</a></li>
    <span class="navbar-text">&nbsp;&nbsp;</span>
    <li class="nav-item"><a class="nav-link" href="../Sampling_and_Reconstruction/Further_Reading.html">(Previous: Further Reading)</a></li>
  </ul>

  <ul class="nav navbar-nav ml-auto d-none d-md-block">
        <li class="nav-item"><div class="gcse-search"></div></li>
    </ul>
  <ul class="nav navbar-nav d-block d-md-none">
        <li class="nav-item"><div class="gcse-search"></div></li>
    </ul>
  <ul class="nav navbar-nav d-block">
    <li class="nav-item"><button class="displaymode" onclick="TogglePBRTDisplayMode()"></button></li>
  </ul>
</nav>

<div class="maincontainer">
<div class="container-fluid">

<div class="row">
<div class="col-md-1 col-lg-2 leftcolumn">

</div>
<div class="col-md-10 col-lg-8">

</div> <!-- col-md-10 col-lg-8 -->
<div class="col-md-1 col-lg-2">

</div> <!-- col-md-1 col-lg-2 -->
</div>  <!-- row -->

<div class="row">
<div class="col-md-1 col-lg-2 leftcolumn">
<a href="#"><i class="fas fa-link "></i></a>
</div>
<div class="col-md-10 col-lg-8">
<h2>Exercises</h2><p>


</p>
<p></p>
<ol>

 <li class="exercise"><span class="exerciseicon">&#9313;</span> 
It&rsquo;s possible to implement a specialized version of
<a href="../Sampling_and_Reconstruction/The_Halton_Sampler.html#ScrambledRadicalInverse"><tt>ScrambledRadicalInverse()</tt></a> for base 2, along the lines of the
implementation in <a href="../Sampling_and_Reconstruction/The_Halton_Sampler.html#RadicalInverse"><tt>RadicalInverse()</tt></a>. Determine how to map the random
digit permutation to a single bitwise operation and implement this
approach.  Compare the values computed to those generated by the current
implementation to ensure your method is correct and measure how much faster
yours is by writing a small benchmark program.

 <li class="exercise"><span class="exerciseicon">&#9313;</span> Currently, the third through fifth dimensions of each
sample vector are consumed for time and lens samples, even though not all
scenes need these sample values. Because lower dimensions in the sample
vector are often better distributed than later ones, this can cause an
unnecessary reduction in image quality.

Modify <tt>pbrt</tt> so that the camera can report its sample requirements and
then use this information when samples are requested to initialize
<a href="../Camera_Models/Camera_Model.html#CameraSample"><tt>CameraSample</tt></a>s. Don&rsquo;t forget to update the value of
<a href="../Sampling_and_Reconstruction/Sampling_Interface.html#GlobalSampler::arrayStartDim"><tt>GlobalSampler::arrayStartDim</tt></a>.  Render images with the
<a href="../Light_Transport_I_Surface_Reflection/Direct_Lighting.html#DirectLightingIntegrator"><tt>DirectLightingIntegrator</tt></a> and compare results to the current
implementation.  Do you see an improvement? How do results differ with
different samplers? How do you explain any differences you see across
samplers?

 <li class="exercise"><span class="exerciseicon">&#9313;</span> Implement the improved multi-jittered sampling method
introduced by Kensler (<a href="Further_Reading.html#cite:Kensler2013">2013</a>) as a new <tt>Sampler</tt> in <tt>pbrt</tt>. Compare
image quality and rendering time to rendering with the
<a href="../Sampling_and_Reconstruction/Stratified_Sampling.html#StratifiedSampler"><tt>StratifiedSampler</tt></a>, the <a href="../Sampling_and_Reconstruction/The_Halton_Sampler.html#HaltonSampler"><tt>HaltonSampler</tt></a>, and the
<a href="../Sampling_and_Reconstruction/Sobol_Sampler.html#SobolSampler"><tt>SobolSampler</tt></a>.

 <li class="exercise"><span class="exerciseicon">&#9313;</span> Keller (<a href="Further_Reading.html#cite:Keller2004">2004</a>) and Dammertz and Keller (<a href="Further_Reading.html#cite:Dammertz2008b">2008b</a>) described the
application of <em>rank-1 lattices</em> to image synthesis.  Rank-1 lattices
are another way of efficiently generating high-quality low-discrepancy
sequences of sample points.  Read their papers and implement a
<tt>Sampler</tt> based on this approach.  Compare results to the other
samplers in <tt>pbrt</tt>.
 
 <li class="exercise"><span class="exerciseicon">&#9313;</span> With <tt>pbrt</tt>&rsquo;s current <a href="../Sampling_and_Reconstruction/Film_and_the_Imaging_Pipeline.html#FilmTile"><tt>FilmTile</tt></a> implementation, the
pixel values in an image may change by small amounts if an image is
rerendered, due to threads finishing tiles in different orders over
subsequent runs.  For example, a pixel that had a final value that came
from samples from three different image sampling tiles, <svg xmlns:xlink="http://www.w3.org/1999/xlink" width="12.226ex" height="2.343ex" style="vertical-align: -0.671ex;" viewBox="0 -719.6 5264.1 1008.6" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">v 1 plus v 2 plus v 3</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-LATINMODERNNORMAL-1D463" d="M468 372c0 -52 -57 -383 -225 -383c-46 0 -134 16 -134 124c0 43 13 89 57 205c7 18 17 45 17 70c0 32 -17 32 -25 32c-29 0 -72 -23 -101 -124c-5 -16 -6 -18 -16 -18c0 0 -12 0 -12 10c0 9 38 154 132 154c50 0 82 -37 82 -82c0 -19 -5 -33 -12 -50 c-31 -83 -58 -156 -58 -212c0 -52 23 -87 74 -87c117 0 178 229 178 271c0 36 -13 62 -34 82c-11 11 -16 17 -16 30c0 22 24 48 49 48c18 0 44 -16 44 -70Z"></path>
<path stroke-width="1" id="E1-LATINMODERNMAIN-31" d="M419 0c-35 3 -122 3 -162 3s-127 0 -162 -3v31h32c90 0 93 12 93 48v518c-52 -26 -111 -26 -131 -26v31c32 0 120 0 182 64c23 0 23 -2 23 -26v-561c0 -37 3 -48 93 -48h32v-31Z"></path>
<path stroke-width="1" id="E1-LATINMODERNMAIN-2B" d="M722 250c0 -11 -9 -20 -20 -20h-293v-293c0 -11 -9 -20 -20 -20s-20 9 -20 20v293h-293c-11 0 -20 9 -20 20s9 20 20 20h293v293c0 11 9 20 20 20s20 -9 20 -20v-293h293c11 0 20 -9 20 -20Z"></path>
<path stroke-width="1" id="E1-LATINMODERNMAIN-32" d="M449 174l-28 -174h-371c0 24 0 26 11 37l192 214c55 62 105 141 105 221c0 82 -43 163 -134 163c-58 0 -112 -37 -135 -102c3 1 5 1 13 1c35 0 53 -26 53 -52c0 -41 -35 -53 -52 -53c-3 0 -53 0 -53 56c0 89 74 181 187 181c122 0 212 -80 212 -194 c0 -100 -60 -154 -216 -292l-106 -103h180c22 0 88 0 95 8c10 15 17 59 22 89h25Z"></path>
<path stroke-width="1" id="E1-LATINMODERNMAIN-33" d="M457 171c0 -102 -91 -193 -213 -193c-109 0 -202 66 -202 157c0 44 32 58 56 58c29 0 56 -20 56 -56c0 -38 -31 -60 -66 -55c35 -59 110 -76 153 -76c44 0 113 29 113 165c0 98 -37 166 -119 166h-44c-17 0 -24 0 -24 11c0 10 7 11 15 12c7 0 31 2 39 3c25 1 59 4 89 52 c26 44 28 102 28 114c0 90 -55 112 -96 112c-36 0 -102 -13 -133 -62c15 0 62 0 62 -50c0 -29 -20 -51 -51 -51c-29 0 -51 19 -51 52c0 76 76 136 177 136c96 0 184 -56 184 -138c0 -79 -58 -149 -140 -176c104 -21 167 -99 167 -181Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-LATINMODERNNORMAL-1D463" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-LATINMODERNMAIN-31" x="686" y="-213"></use>
 <use xlink:href="#E1-LATINMODERNMAIN-2B" x="1161" y="0"></use>
<g transform="translate(2162,0)">
 <use xlink:href="#E1-LATINMODERNNORMAL-1D463" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-LATINMODERNMAIN-32" x="686" y="-213"></use>
</g>
 <use xlink:href="#E1-LATINMODERNMAIN-2B" x="3323" y="0"></use>
<g transform="translate(4324,0)">
 <use xlink:href="#E1-LATINMODERNNORMAL-1D463" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-LATINMODERNMAIN-33" x="686" y="-213"></use>
</g>
</g>
</svg>,
may sometimes have its value computed as <svg xmlns:xlink="http://www.w3.org/1999/xlink" width="14.036ex" height="2.843ex" style="vertical-align: -0.838ex;" viewBox="0 -863.1 6043.1 1223.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">left-parenthesis v 1 plus v 2 right-parenthesis plus v 3</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-LATINMODERNMAIN-28" d="M332 -238c0 -5 -5 -10 -10 -10c-2 0 -4 1 -6 2c-110 83 -215 283 -215 454v84c0 171 105 371 215 454c2 1 4 2 6 2c5 0 10 -5 10 -10c0 -3 -2 -6 -4 -8c-104 -78 -173 -278 -173 -438v-84c0 -160 69 -360 173 -438c2 -2 4 -5 4 -8Z"></path>
<path stroke-width="1" id="E1-LATINMODERNNORMAL-1D463" d="M468 372c0 -52 -57 -383 -225 -383c-46 0 -134 16 -134 124c0 43 13 89 57 205c7 18 17 45 17 70c0 32 -17 32 -25 32c-29 0 -72 -23 -101 -124c-5 -16 -6 -18 -16 -18c0 0 -12 0 -12 10c0 9 38 154 132 154c50 0 82 -37 82 -82c0 -19 -5 -33 -12 -50 c-31 -83 -58 -156 -58 -212c0 -52 23 -87 74 -87c117 0 178 229 178 271c0 36 -13 62 -34 82c-11 11 -16 17 -16 30c0 22 24 48 49 48c18 0 44 -16 44 -70Z"></path>
<path stroke-width="1" id="E1-LATINMODERNMAIN-31" d="M419 0c-35 3 -122 3 -162 3s-127 0 -162 -3v31h32c90 0 93 12 93 48v518c-52 -26 -111 -26 -131 -26v31c32 0 120 0 182 64c23 0 23 -2 23 -26v-561c0 -37 3 -48 93 -48h32v-31Z"></path>
<path stroke-width="1" id="E1-LATINMODERNMAIN-2B" d="M722 250c0 -11 -9 -20 -20 -20h-293v-293c0 -11 -9 -20 -20 -20s-20 9 -20 20v293h-293c-11 0 -20 9 -20 20s9 20 20 20h293v293c0 11 9 20 20 20s20 -9 20 -20v-293h293c11 0 20 -9 20 -20Z"></path>
<path stroke-width="1" id="E1-LATINMODERNMAIN-32" d="M449 174l-28 -174h-371c0 24 0 26 11 37l192 214c55 62 105 141 105 221c0 82 -43 163 -134 163c-58 0 -112 -37 -135 -102c3 1 5 1 13 1c35 0 53 -26 53 -52c0 -41 -35 -53 -52 -53c-3 0 -53 0 -53 56c0 89 74 181 187 181c122 0 212 -80 212 -194 c0 -100 -60 -154 -216 -292l-106 -103h180c22 0 88 0 95 8c10 15 17 59 22 89h25Z"></path>
<path stroke-width="1" id="E1-LATINMODERNMAIN-29" d="M288 208c0 -171 -105 -371 -215 -454c-2 -1 -4 -2 -6 -2c-5 0 -10 5 -10 10c0 3 2 6 4 8c104 78 173 278 173 438v84c0 160 -69 360 -173 438c-2 2 -4 5 -4 8c0 5 5 10 10 10c2 0 4 -1 6 -2c110 -83 215 -283 215 -454v-84Z"></path>
<path stroke-width="1" id="E1-LATINMODERNMAIN-33" d="M457 171c0 -102 -91 -193 -213 -193c-109 0 -202 66 -202 157c0 44 32 58 56 58c29 0 56 -20 56 -56c0 -38 -31 -60 -66 -55c35 -59 110 -76 153 -76c44 0 113 29 113 165c0 98 -37 166 -119 166h-44c-17 0 -24 0 -24 11c0 10 7 11 15 12c7 0 31 2 39 3c25 1 59 4 89 52 c26 44 28 102 28 114c0 90 -55 112 -96 112c-36 0 -102 -13 -133 -62c15 0 62 0 62 -50c0 -29 -20 -51 -51 -51c-29 0 -51 19 -51 52c0 76 76 136 177 136c96 0 184 -56 184 -138c0 -79 -58 -149 -140 -176c104 -21 167 -99 167 -181Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-LATINMODERNMAIN-28" x="0" y="0"></use>
<g transform="translate(389,0)">
 <use xlink:href="#E1-LATINMODERNNORMAL-1D463" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-LATINMODERNMAIN-31" x="686" y="-213"></use>
</g>
 <use xlink:href="#E1-LATINMODERNMAIN-2B" x="1551" y="0"></use>
<g transform="translate(2551,0)">
 <use xlink:href="#E1-LATINMODERNNORMAL-1D463" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-LATINMODERNMAIN-32" x="686" y="-213"></use>
</g>
 <use xlink:href="#E1-LATINMODERNMAIN-29" x="3491" y="0"></use>
 <use xlink:href="#E1-LATINMODERNMAIN-2B" x="4102" y="0"></use>
<g transform="translate(5103,0)">
 <use xlink:href="#E1-LATINMODERNNORMAL-1D463" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-LATINMODERNMAIN-33" x="686" y="-213"></use>
</g>
</g>
</svg> and sometimes
as <svg xmlns:xlink="http://www.w3.org/1999/xlink" width="14.036ex" height="2.843ex" style="vertical-align: -0.838ex;" viewBox="0 -863.1 6043.1 1223.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">v 1 plus left-parenthesis v 2 plus v 3 right-parenthesis</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-LATINMODERNNORMAL-1D463" d="M468 372c0 -52 -57 -383 -225 -383c-46 0 -134 16 -134 124c0 43 13 89 57 205c7 18 17 45 17 70c0 32 -17 32 -25 32c-29 0 -72 -23 -101 -124c-5 -16 -6 -18 -16 -18c0 0 -12 0 -12 10c0 9 38 154 132 154c50 0 82 -37 82 -82c0 -19 -5 -33 -12 -50 c-31 -83 -58 -156 -58 -212c0 -52 23 -87 74 -87c117 0 178 229 178 271c0 36 -13 62 -34 82c-11 11 -16 17 -16 30c0 22 24 48 49 48c18 0 44 -16 44 -70Z"></path>
<path stroke-width="1" id="E1-LATINMODERNMAIN-31" d="M419 0c-35 3 -122 3 -162 3s-127 0 -162 -3v31h32c90 0 93 12 93 48v518c-52 -26 -111 -26 -131 -26v31c32 0 120 0 182 64c23 0 23 -2 23 -26v-561c0 -37 3 -48 93 -48h32v-31Z"></path>
<path stroke-width="1" id="E1-LATINMODERNMAIN-2B" d="M722 250c0 -11 -9 -20 -20 -20h-293v-293c0 -11 -9 -20 -20 -20s-20 9 -20 20v293h-293c-11 0 -20 9 -20 20s9 20 20 20h293v293c0 11 9 20 20 20s20 -9 20 -20v-293h293c11 0 20 -9 20 -20Z"></path>
<path stroke-width="1" id="E1-LATINMODERNMAIN-28" d="M332 -238c0 -5 -5 -10 -10 -10c-2 0 -4 1 -6 2c-110 83 -215 283 -215 454v84c0 171 105 371 215 454c2 1 4 2 6 2c5 0 10 -5 10 -10c0 -3 -2 -6 -4 -8c-104 -78 -173 -278 -173 -438v-84c0 -160 69 -360 173 -438c2 -2 4 -5 4 -8Z"></path>
<path stroke-width="1" id="E1-LATINMODERNMAIN-32" d="M449 174l-28 -174h-371c0 24 0 26 11 37l192 214c55 62 105 141 105 221c0 82 -43 163 -134 163c-58 0 -112 -37 -135 -102c3 1 5 1 13 1c35 0 53 -26 53 -52c0 -41 -35 -53 -52 -53c-3 0 -53 0 -53 56c0 89 74 181 187 181c122 0 212 -80 212 -194 c0 -100 -60 -154 -216 -292l-106 -103h180c22 0 88 0 95 8c10 15 17 59 22 89h25Z"></path>
<path stroke-width="1" id="E1-LATINMODERNMAIN-33" d="M457 171c0 -102 -91 -193 -213 -193c-109 0 -202 66 -202 157c0 44 32 58 56 58c29 0 56 -20 56 -56c0 -38 -31 -60 -66 -55c35 -59 110 -76 153 -76c44 0 113 29 113 165c0 98 -37 166 -119 166h-44c-17 0 -24 0 -24 11c0 10 7 11 15 12c7 0 31 2 39 3c25 1 59 4 89 52 c26 44 28 102 28 114c0 90 -55 112 -96 112c-36 0 -102 -13 -133 -62c15 0 62 0 62 -50c0 -29 -20 -51 -51 -51c-29 0 -51 19 -51 52c0 76 76 136 177 136c96 0 184 -56 184 -138c0 -79 -58 -149 -140 -176c104 -21 167 -99 167 -181Z"></path>
<path stroke-width="1" id="E1-LATINMODERNMAIN-29" d="M288 208c0 -171 -105 -371 -215 -454c-2 -1 -4 -2 -6 -2c-5 0 -10 5 -10 10c0 3 2 6 4 8c104 78 173 278 173 438v84c0 160 -69 360 -173 438c-2 2 -4 5 -4 8c0 5 5 10 10 10c2 0 4 -1 6 -2c110 -83 215 -283 215 -454v-84Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-LATINMODERNNORMAL-1D463" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-LATINMODERNMAIN-31" x="686" y="-213"></use>
 <use xlink:href="#E1-LATINMODERNMAIN-2B" x="1161" y="0"></use>
 <use xlink:href="#E1-LATINMODERNMAIN-28" x="2162" y="0"></use>
<g transform="translate(2551,0)">
 <use xlink:href="#E1-LATINMODERNNORMAL-1D463" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-LATINMODERNMAIN-32" x="686" y="-213"></use>
</g>
 <use xlink:href="#E1-LATINMODERNMAIN-2B" x="3713" y="0"></use>
<g transform="translate(4714,0)">
 <use xlink:href="#E1-LATINMODERNNORMAL-1D463" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-LATINMODERNMAIN-33" x="686" y="-213"></use>
</g>
 <use xlink:href="#E1-LATINMODERNMAIN-29" x="5653" y="0"></use>
</g>
</svg>.  Due to floating-point round-off, these two
values may be different.  While these differences aren&rsquo;t normally a
problem, they wreak havoc with automated testing scripts that might want to
verify that a believed-to-be-innocuous change to the system didn&rsquo;t actually
cause any differences in rendered images.

Modify <a href="../Sampling_and_Reconstruction/Film_and_the_Imaging_Pipeline.html#Film::MergeFilmTile"><tt>Film::MergeFilmTile()</tt></a> so that it merges tiles in a consistent
order so that final pixel values don&rsquo;t suffer from this inconsistency.
(For example, your implementation might buffer up <tt>FilmTile</tt>s and only
merge a tile when all neighboring tiles above and to its left have already
been merged.)  Ensure that your implementation doesn&rsquo;t introduce any
meaningful performance regression.  Measure the additional memory usage due
to longer lived <tt>FilmTile</tt>s; how does it relate to total memory usage?
  
 <li class="exercise"><span class="exerciseicon">&#9313;</span> As mentioned in Section&nbsp;<a href="../Sampling_and_Reconstruction/Film_and_the_Imaging_Pipeline.html#sec:image-pipeline">7.9</a>, the
<a href="../Sampling_and_Reconstruction/Film_and_the_Imaging_Pipeline.html#Film::AddSplat"><tt>Film::AddSplat()</tt></a> method doesn&rsquo;t use a filter function but instead just
splats the sample to the single pixel it&rsquo;s closest to, effectively using a
box filter.  In order to apply an arbitrary filter, the filter must be
normalized so that it integrates to one over its domain; this constraint
isn&rsquo;t currently required of <a href="../Sampling_and_Reconstruction/Image_Reconstruction.html#Filter"><tt>Filter</tt></a>s by <tt>pbrt</tt>.  Modify the computation
of <tt>filterTable</tt> in the <a href="../Sampling_and_Reconstruction/Film_and_the_Imaging_Pipeline.html#Film"><tt>Film</tt></a> constructor so that the tabulated
function is normalized.  (Don&rsquo;t forget that the table only stores
one-quarter of the function&rsquo;s extent when computing the normalization factor.)
Then modify the implementation of the <tt>AddSplat()</tt> method to use this
filter.  Investigate the execution time and image quality differences that
result.

 <li class="exercise"><span class="exerciseicon">&#9312;</span> Modify <tt>pbrt</tt> to create images where
the value stored in the <tt>Film</tt> for each camera ray is proportional to
the time taken to compute the ray&rsquo;s radiance.  (A 1-pixel-wide box filter
is probably the most useful filter for this exercise.)  Render images of a
variety of scenes with this technique.  What insight about the system&rsquo;s
performance do the resulting images bring?  You may need to scale pixel
values or take their logarithm to see meaningful variation when you view them.

 <li class="exercise"><span class="exerciseicon">&#9313;</span> One of the advantages of the linearity assumption in
radiometry is that the final image of a scene is the same as the sum of
individual images that account for each light source&rsquo;s contribution
(assuming a floating-point image file format is used that doesn&rsquo;t clip
pixel radiance values).  An implication of this property is that if a
renderer creates a separate image for each light source, it is possible to
write interactive lighting design tools that make it possible to quickly
see the effects of scaling the contributions of individual lights in the
scene without needing to rerender it from scratch. Instead, a light&rsquo;s
individual image can be scaled and the final image regenerated by summing
all of the light images again.  (This technique was first applied for opera
lighting design by Dorsey, Sillion, and Greenberg (<a href="Further_Reading.html#cite:Dorsey:1991:DAS">1991</a>).)  Modify
<tt>pbrt</tt> to output a separate image for each of the lights in the scene, and
write an interactive lighting design tool that uses them in this manner.

 <li class="exercise"><span class="exerciseicon">&#9314;</span> Mitchell and Netravali (<a href="Further_Reading.html#cite:Mitchell88">1988</a>) noted that there is a family of
reconstruction filters that use both the value of a function and its
derivative at the point to do substantially better reconstruction than if
just the value of the function is known.  Furthermore, they report that
they have derived closed-form expressions for the screen space derivatives
of Lambertian and Phong reflection models, although they do not include
these expressions in their paper.  Investigate derivative-based
reconstruction, and extend <tt>pbrt</tt> to support this technique.  Because it
will likely be difficult to derive expressions for the screen space
derivatives for general shapes and BSDF models, investigate approximations
based on finite differencing.  Techniques built on the ideas behind the ray
differentials of Section&nbsp;<a href="../Texture/Sampling_and_Antialiasing.html#sec:texture-anti-aliasing">10.1</a> may be fruitful
for this effort.

 <li class="exercise"><span class="exerciseicon">&#9314;</span> Image-based rendering is the general name for a set of techniques
that use one or more images of a scene to synthesize new images from
viewpoints different from the original ones.  One such approach is
light field rendering, where a set of images from a densely spaced set of
positions is used (<a href="Further_Reading.html#cite:Levoy96">Levoy and Hanrahan 1996</a>; Gortler et al.&nbsp;<a href="Further_Reading.html#cite:Gortler96">1996</a>).
Read these two papers on
light fields, and modify <tt>pbrt</tt> to directly generate light fields of scenes,
without requiring that the renderer be run multiple times, once for each
camera position.  It will probably be necessary to write a specialized
<tt>Camera</tt>, <tt>Sampler</tt>, and <tt>Film</tt> to do this.  Also, write an
interactive light field viewer that loads light fields generated by your
implementation and generates new views of the scene.

 <li class="exercise"><span class="exerciseicon">&#9314;</span> Rather than just storing spectral values 
in an image, it&rsquo;s often useful to store additional
information about the objects in the scene that were visible at each pixel.
See, for example, the SIGGRAPH papers by Perlin (<a href="Further_Reading.html#cite:Perlin85">1985a</a>) and Saito and Takahashi (<a href="Further_Reading.html#cite:Saito90">1990</a>).  For example, if the 3D position, surface normal,
and BRDF of the object at each pixel are stored, then the scene
can be efficiently rerendered after moving the light
sources (<a href="Further_Reading.html#cite:Gershbein00">Gershbein and Hanrahan 2000</a>).  Alternatively, if each sample stores
information about all of the objects visible along its camera ray, rather
than just the first one, new images from shifted viewpoints can be
rerendered (Shade et al.&nbsp;<a href="Further_Reading.html#cite:Shade98">1998</a>).  Investigate representations for deep
frame buffers and algorithms that use them; extend <tt>pbrt</tt> to support 
the creation of images like these, and develop tools that operate on them.

 <li class="exercise"><span class="exerciseicon">&#9313;</span> Implement a median filter for image reconstruction: for
each pixel, store the median of all of the samples within a filter extent
around it.  This task is complicated by the fact that filters in the
current <tt>Film</tt> implementation must be <em>linear</em>&mdash;the value of the
filter function is determined solely by the position of the sample with
respect to the pixel position, and the value of the sample has no impact on
the value of the filter function.  Because the implementation assumes that
filters are linear, and because it doesn&rsquo;t store sample values after adding
their contribution to the image, implementing the median filter will
require generalizing the <a href="../Sampling_and_Reconstruction/Film_and_the_Imaging_Pipeline.html#Film"><tt>Film</tt></a> or developing a new <a href="../Sampling_and_Reconstruction/Film_and_the_Imaging_Pipeline.html#Film"><tt>Film</tt></a>
implementation.

Render images using integrators like the <a href="../Light_Transport_I_Surface_Reflection/Path_Tracing.html#PathIntegrator"><tt>PathIntegrator</tt></a> that have
objectionable image noise with regular image filters.  How successful is
the median filter at reducing noise?  Are there visual shortcomings to
using the median filter?  Can you implement this approach without needing
to store all of the image sample values before computing final pixel
values?

 <li class="exercise"><span class="exerciseicon">&#9313;</span> An alternative to the median filter is to discard the
sample with the lowest contribution and the sample with the largest
contribution in a pixel&rsquo;s filter region.  This approach uses more of the
information gathered during sampling.
Implement this approach and compare
the results to the median filter.

 <li class="exercise"><span class="exerciseicon">&#9314;</span> Implement the discontinuity buffer, as described by Keller
and collaborators (Keller <a href="Further_Reading.html#cite:Keller98">1998</a>; Wald et&nbsp;al. <a href="Further_Reading.html#cite:Wald02">2002</a>).  You will probably need
to modify the interface to the <a href="../Introduction/pbrt_System_Overview.html#Integrator"><tt>Integrator</tt></a>s so that they can
separately return direct and indirect illumination contributions and then
pass these separately to the <tt>Film</tt>.  Render images showing its
effectiveness when rendering images with indirect illumination.

 <li class="exercise"><span class="exerciseicon">&#9314;</span> Implement one of the recent adaptive sampling and
reconstruction techniques such as the ones described by Hachisuka et&nbsp;al. (<a href="Further_Reading.html#cite:Hachisuka08">2008a</a>), Egan et&nbsp;al. (<a href="Further_Reading.html#cite:Egan09">2009</a>), Overbeck et&nbsp;al. (<a href="Further_Reading.html#cite:Overbeck09">2009</a>), or Moon et&nbsp;al. (<a href="Further_Reading.html#cite:Moon2014">2014</a>).  How much more efficiently do they generate images of equal
quality than just uniformly sampling at a high rate?  How do they affect
running time for simple scenes where adaptive sampling isn&rsquo;t needed?

 <li class="exercise"><span class="exerciseicon">&#9314;</span> Investigate current research in tone reproduction algorithms
(see, e.g., Reinhard et&nbsp;al. <a href="Further_Reading.html#cite:Reinhard10">2010</a>; <a href="Further_Reading.html#cite:Reinhard2012">2012</a>), and implement one or more
of these algorithms. Use your implementation with a number of scenes
rendered by <tt>pbrt</tt>, and discuss the improvements you see compared to viewing
the images without tone reproduction.

</ol><p>



</p>
<p>

</p>
<p></p>

</div> <!-- col-md-10 col-lg-8 -->
<div class="col-md-1 col-lg-2">

</div> <!-- col-md-1 col-lg-2 -->
</div>  <!-- row -->

</div>  <!-- container-fluid -->
</div>  <!-- maincontainer -->

<nav class="navbar navbar-expand-md">
  <span class="navbar-text"><i>Physically Based Rendering: From Theory To Implementation</i>, &copy; 2004-2021 Matt Pharr, Wenzel Jakob, and Greg Humphreys under the <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/">CC BY-NC-ND 4.0</a> license. (<a href="https://github.com/mmp/pbr-book-website/">github</a>)</span>
  <div class="container">
    <ul class="nav navbar-nav ml-auto">
      <li class="nav-item">Next: <a href="../Reflection_Models.html">Reflection Models</a></li>
    </ul>
  </div>

</nav>

<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
<script>
  $(function () {
    $('[data-toggle="popover"]').popover()
    $('[data-toggle="tooltip"]').tooltip()
   })
</script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy" crossorigin="anonymous"></script>

<script>
// https://stackoverflow.com/a/17535094
// The function actually applying the offset
function offsetAnchor() {
  if (location.hash.length !== 0) {
    window.scrollTo(window.scrollX, window.scrollY - window.innerHeight / 8);
  }
}

// Captures click events of all <a> elements with href starting with #
$(document).on('click', 'a[href^="#"]', function(event) {
  // Click events are captured before hashchanges. Timeout
  // causes offsetAnchor to be called after the page jump.
  window.setTimeout(function() {
    offsetAnchor();
  }, 500);
});

// Set the offset when entering page with hash present in the url
window.setTimeout(offsetAnchor, 1500);
</script>

</body>
</html>
